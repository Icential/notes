For only one feature, there only is one x and the linear regression model is defined as $f_{w,b}(x)=wx+b$

However with multiple features, there are multiple x's such as $x_1,x_2,x_3,...,x_n$
Hence the model is also extended to $f_{w,b}(x)=w_1x_1+w_2x_2+w_3x_3+...+w_nx_n+b$

A new way to think of $b$ is that as a base value assuming all feature values are 0.

Notice that $x$ and $w$ are now arrays or column vectors that store multiple elements
	$x=\vec{x}=[x_1,x_2,x_3,...,x_n]$
	$w=\vec{w}=[w_1,w_2,w_3,...,w_n]$

Therefore the linear regression model can be rewritten with a dot product as: $$f_{\vec{w},b}(\vec{x})=\vec{w}\cdot\vec{x}+b$$
This is also called the multiple linear regression (not multivariate regression)