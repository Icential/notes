![[fittings.png]]
![[fittings 2.png]]

1. A model underfits the data if it doesn't fit the dataset well (big loss; high bias; not seeing important patterns)
2. A model fits the data if there is near minimal loss and low bias. Tends to have good generalization; meaning on seeing untested/unseen data, it should also have minimal loss.
3. A model overfits the data if the model fits way too specifically for one dataset with overly complex functions and will do badly with another unseen dataset (bad generalization, high variation)

You can see the Goldilocks Rule in play here.


How to prevent overfitting:
- Get more training examples to fit more general patterns
- Don't use too many features (only include those with high correlation to label; this is called feature selection)
- [[9.3-5 Regularization]] (keeps all features unlike feature selection by selecting specific weights for specific features to not overfit it; usually big parameters are dealt with small weights)